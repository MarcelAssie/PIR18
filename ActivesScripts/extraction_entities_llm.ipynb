{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T22:54:13.357579Z",
     "start_time": "2024-10-20T22:54:13.352376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from ActivesScripts.toolbox import start \n",
    "import time"
   ],
   "id": "1675a87a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T22:54:13.388566Z",
     "start_time": "2024-10-20T22:54:13.382236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Création du dossier de résultats\n",
    "results_path = \"../OutputDatallm\"\n",
    "os.makedirs(results_path, exist_ok=True)"
   ],
   "id": "b60d8e2e6d3e4532",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "85847c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T22:54:13.448521Z",
     "start_time": "2024-10-20T22:54:13.441050Z"
    }
   },
   "source": [
    "def entities_extractions(dossier, model= \"mistral-7b-instruct-v0.1.Q4_K_M.gguf\"):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Récupération du numéro du dossier ODD (derniers deux chiffres)\n",
    "    odd_number = dossier[-2:]\n",
    "    \n",
    "    # Création du dossier du ODD dans le dossier de résultats\n",
    "    dossier_path = f\"{results_path}/ODD{odd_number}\"\n",
    "    os.makedirs(dossier_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nDébut de traitement de l'ODD {odd_number}...\")\n",
    "\n",
    "    # Liste des fichiers texte à traiter\n",
    "    txt_files = [fichier for fichier in os.listdir(dossier)\n",
    "                 if fichier.endswith(\".txt\") and \"keywords\" not in fichier]\n",
    "\n",
    "    keywords_ODD = []\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        keywords = start(odd_number, f\"{dossier}/{txt_file}\", model)\n",
    "        keywords_ODD.extend(keywords)\n",
    "\n",
    "    # Stockage des résultats en dataframe\n",
    "    df = pd.DataFrame(keywords_ODD, columns=[\"ODD\", \"Cible\", \"Mots-cles\"])\n",
    "    \n",
    "    # Exporter les données en csv\n",
    "    df.to_csv(f\"{dossier_path}/ODD{odd_number}_keywords.csv\", index=False)\n",
    "   \n",
    "    end_time = time.time()\n",
    "    duree = end_time - start_time\n",
    "    print(f\"...Fin de traitement de l'ODD {odd_number}\\nDurée d'exécution : {duree:.4f} secondes.\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T22:55:31.233025Z",
     "start_time": "2024-10-20T22:54:13.474940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = \"mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "entities_extractions(\"../MedaDocx/ODD01\", model)"
   ],
   "id": "c59b2b67706e088d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Début de traitement de l'ODD 01...\n",
      "\n",
      "Extraction du texte...\n",
      "\n",
      "Découpage du texte..\n",
      "\n",
      "Extraction des mots-clés...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "262e7979e8db476181c038ace3d177ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c81114ca3f86401a9165fb23e374ffd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmistral-7b-instruct-v0.1.Q4_K_M.gguf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mentities_extractions\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../MedaDocx/ODD01\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[10], line 21\u001B[0m, in \u001B[0;36mentities_extractions\u001B[1;34m(dossier, model)\u001B[0m\n\u001B[0;32m     18\u001B[0m keywords_ODD \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m txt_file \u001B[38;5;129;01min\u001B[39;00m txt_files:\n\u001B[1;32m---> 21\u001B[0m     keywords \u001B[38;5;241m=\u001B[39m \u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43modd_number\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdossier\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtxt_file\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m     keywords_ODD\u001B[38;5;241m.\u001B[39mextend(keywords)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Stockage des résultats en dataframe\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\ActivesScripts\\toolbox.py:118\u001B[0m, in \u001B[0;36mstart\u001B[1;34m(odd_number, txt_file, model)\u001B[0m\n\u001B[0;32m    115\u001B[0m chunks \u001B[38;5;241m=\u001B[39m chunk_text(document_content)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;66;03m# Extraire les mots-clés de chaque morceau\u001B[39;00m\n\u001B[1;32m--> 118\u001B[0m keywords \u001B[38;5;241m=\u001B[39m \u001B[43mextract_keywords_from_chunks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;66;03m# Aplatir les mots-clés dans une unique liste\u001B[39;00m\n\u001B[0;32m    121\u001B[0m list_keywords \u001B[38;5;241m=\u001B[39m [keyword \u001B[38;5;28;01mfor\u001B[39;00m sublist \u001B[38;5;129;01min\u001B[39;00m keywords \u001B[38;5;28;01mfor\u001B[39;00m keyword \u001B[38;5;129;01min\u001B[39;00m sublist]\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\ActivesScripts\\toolbox.py:78\u001B[0m, in \u001B[0;36mextract_keywords_from_chunks\u001B[1;34m(chunks, test_model)\u001B[0m\n\u001B[0;32m     76\u001B[0m llm \u001B[38;5;241m=\u001B[39m TextGeneration(generator, prompt\u001B[38;5;241m=\u001B[39mprompt)\n\u001B[0;32m     77\u001B[0m kw_model \u001B[38;5;241m=\u001B[39m KeyLLM(llm)\n\u001B[1;32m---> 78\u001B[0m extracted_keywords \u001B[38;5;241m=\u001B[39m \u001B[43mkw_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_keywords\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# Nettoyage préliminaire des mots-clés extraits\u001B[39;00m\n\u001B[0;32m     81\u001B[0m cleaned_keywords \u001B[38;5;241m=\u001B[39m [kw\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m* \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;28;01mfor\u001B[39;00m kw \u001B[38;5;129;01min\u001B[39;00m extracted_keywords[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m kw]\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\keybert\\_llm.py:126\u001B[0m, in \u001B[0;36mKeyLLM.extract_keywords\u001B[1;34m(self, docs, check_vocab, candidate_keywords, threshold, embeddings)\u001B[0m\n\u001B[0;32m    123\u001B[0m         keywords \u001B[38;5;241m=\u001B[39m [in_cluster_keywords[index] \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(docs))]\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;66;03m# Extract keywords using a Large Language Model (LLM)\u001B[39;00m\n\u001B[1;32m--> 126\u001B[0m     keywords \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_keywords\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcandidate_keywords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;66;03m# Only extract keywords that appear in the input document\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_vocab:\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\keybert\\llm\\_textgeneration.py:116\u001B[0m, in \u001B[0;36mTextGeneration.extract_keywords\u001B[1;34m(self, documents, candidate_keywords)\u001B[0m\n\u001B[0;32m    113\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m prompt\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[CANDIDATES]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(candidates))\n\u001B[0;32m    115\u001B[0m \u001B[38;5;66;03m# Extract result from generator and use that as label\u001B[39;00m\n\u001B[1;32m--> 116\u001B[0m keywords \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpipeline_kwargs\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(prompt, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    117\u001B[0m keywords \u001B[38;5;241m=\u001B[39m [keyword\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;28;01mfor\u001B[39;00m keyword \u001B[38;5;129;01min\u001B[39;00m keywords\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[0;32m    118\u001B[0m all_keywords\u001B[38;5;241m.\u001B[39mappend(keywords)\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:272\u001B[0m, in \u001B[0;36mTextGenerationPipeline.__call__\u001B[1;34m(self, text_inputs, **kwargs)\u001B[0m\n\u001B[0;32m    270\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(chats, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 272\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1268\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[0;32m   1261\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[0;32m   1262\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1265\u001B[0m         )\n\u001B[0;32m   1266\u001B[0m     )\n\u001B[0;32m   1267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1275\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[0;32m   1273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[0;32m   1274\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[1;32m-> 1275\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1276\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[0;32m   1277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1175\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m   1173\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m   1174\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 1175\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1176\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:370\u001B[0m, in \u001B[0;36mTextGenerationPipeline._forward\u001B[1;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[0;32m    367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration_config\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m generate_kwargs:\n\u001B[0;32m    368\u001B[0m     generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration_config\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneration_config\n\u001B[1;32m--> 370\u001B[0m generated_sequence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    371\u001B[0m out_b \u001B[38;5;241m=\u001B[39m generated_sequence\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2047\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   2039\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[0;32m   2040\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   2041\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[0;32m   2042\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[0;32m   2043\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   2044\u001B[0m     )\n\u001B[0;32m   2046\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[1;32m-> 2047\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2048\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2049\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2050\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2051\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2052\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2053\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2054\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2055\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2057\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[0;32m   2058\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[0;32m   2059\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[0;32m   2060\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   2061\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2066\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[0;32m   2067\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3007\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[0;32m   3004\u001B[0m model_inputs\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_hidden_states\u001B[39m\u001B[38;5;124m\"\u001B[39m: output_hidden_states} \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;28;01melse\u001B[39;00m {})\n\u001B[0;32m   3006\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[1;32m-> 3007\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   3009\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[0;32m   3010\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\ctransformers\\transformers.py:74\u001B[0m, in \u001B[0;36mCTransformersModel.forward\u001B[1;34m(self, input_ids, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m     72\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m tokens\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m     73\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m llm\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(tokens)\n\u001B[1;32m---> 74\u001B[0m     \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m     logits\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mtensor(llm\u001B[38;5;241m.\u001B[39mlogits)\u001B[38;5;241m.\u001B[39mreshape([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]))\n\u001B[0;32m     76\u001B[0m logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(logits)\n",
      "File \u001B[1;32m~\\Desktop\\Ensg\\Semestre3\\Projet_Recherche\\Scripts\\venv\\Lib\\site-packages\\ctransformers\\llm.py:403\u001B[0m, in \u001B[0;36mLLM.eval\u001B[1;34m(self, tokens, batch_size, threads)\u001B[0m\n\u001B[0;32m    399\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    400\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of tokens (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_past\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39mn_tokens\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exceeded maximum context length (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    401\u001B[0m     )\n\u001B[0;32m    402\u001B[0m tokens \u001B[38;5;241m=\u001B[39m (c_int \u001B[38;5;241m*\u001B[39m n_tokens)(\u001B[38;5;241m*\u001B[39mtokens)\n\u001B[1;32m--> 403\u001B[0m status \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctransformers_llm_batch_eval\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m status:\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to evaluate tokens.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "9badf116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T22:55:31.239309600Z",
     "start_time": "2024-10-20T22:31:01.112998Z"
    }
   },
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Exécution de tous les ODD\n",
    "#     path = \"../MedaDocx\"\n",
    "#     odd_files = os.listdir(path)\n",
    "#     for odd_file in odd_files:\n",
    "#         entities_extractions(f\"{path}/{odd_file}\")\n",
    "#         print(\"----------------------------------------------------------------------------------------------------------\")\n"
   ],
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
