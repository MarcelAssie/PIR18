{
 "cells": [
  {
   "cell_type": "code",
   "id": "1675a87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T14:00:38.209233Z",
     "start_time": "2024-11-09T14:00:32.599503Z"
    }
   },
   "source": [
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os, sys, pandas as pd"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanm\\Desktop\\Ensg\\Semestre3\\ProjetRecherche\\PIR18\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T14:00:38.778679Z",
     "start_time": "2024-11-09T14:00:38.217238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "from Scripts.toolbox import read_txt_file, filter_similar_entities"
   ],
   "id": "882a5c337483f764",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\jeanm\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T14:00:39.009975Z",
     "start_time": "2024-11-09T14:00:39.005880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dossier de stockage de toutes les données\n",
    "results_path = \"../Output/DataLM\"\n",
    "os.makedirs(results_path, exist_ok=True)"
   ],
   "id": "6da68e5ef2b0534b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T14:00:40.614616Z",
     "start_time": "2024-11-09T14:00:39.025782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargement du modèle d'extraction des données\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ],
   "id": "79d0dbbbf640b727",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "85847c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T14:00:40.649595Z",
     "start_time": "2024-11-09T14:00:40.639582Z"
    }
   },
   "source": [
    "def entities_extractions(dossier):\n",
    "    \"\"\"\n",
    "    Extrait les mots-clés de fichiers texte dans un dossier et enregistre les résultats dans des fichiers séparés.\n",
    "\n",
    "    Paramètres:\n",
    "        dossier : str\n",
    "    Chemin vers le dossier contenant les fichiers texte (.txt).\n",
    "    \"\"\"\n",
    "\n",
    "    # Sous dossier de stockage des différents ODD\n",
    "    odd_number = dossier[-2:]\n",
    "    dossier_path = f\"{results_path}/ODD{odd_number}\"\n",
    "    os.makedirs(dossier_path, exist_ok=True)\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"\\nDébut de traitement de l'ODD {odd_number}...\")\n",
    "\n",
    "    # Liste des noms de fichiers texte dans le dossier\n",
    "    # J'utilise la condition supplémentaire pour éviter de sélectionner les fichiers traités\n",
    "    txt_files = [fichier for fichier in os.listdir(dossier)\n",
    "                 if fichier.endswith(\".txt\") and \"keywords\" not in fichier]\n",
    "\n",
    "    keywords_ODD = []\n",
    "    print(\"Extraction des mots-clés...\\n\")\n",
    "    for txt_file in txt_files:\n",
    "        # Convertir le fichier texte en une chaîne de caractères\n",
    "        data = read_txt_file(f\"{dossier}/{txt_file}\")\n",
    "\n",
    "        # Configurer le modèle KeyBert pour l'extraction des mots-clés\n",
    "        kw_model = KeyBERT(model=sentence_model)\n",
    "        keywords = kw_model.extract_keywords(\n",
    "            data,\n",
    "            keyphrase_ngram_range=(1, 2),   # Taille de mots/phrases clé(e)s\n",
    "            stop_words='english',           # Eliminer les mots usuels en anglais\n",
    "            use_maxsum=True,                # Eviter de sélectionner trop proches de sens\n",
    "            nr_candidates=20,               # Nombre d'éléments à étudier\n",
    "            top_n=10                        # Nombre d'éléments choisis\n",
    "        )\n",
    "        \n",
    "        # Filtrer les entités similaires\n",
    "        entities_filtered = filter_similar_entities(keywords, threshold=80)\n",
    "\n",
    "        # Filtrer les résultats par score et cible\n",
    "        filtered_keywords = [(kw[0], kw[1], txt_file[12:14]) for kw in entities_filtered if kw[1] > 0.5]\n",
    "        keywords_ODD.extend(filtered_keywords)\n",
    "\n",
    "        # Enregistrer les mots-clés\n",
    "        metadata = txt_file.replace(\".txt\",\"\")\n",
    "        metadata = metadata.replace(\"Metadata-\", \"Indicateur_\")\n",
    "        output_path_file = f\"{dossier_path}/{metadata}.txt\"\n",
    "        with open(output_path_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"Mots-clés extraits et scores :\\n\")\n",
    "            f.write(\"----------------------------------------------------\\n\")\n",
    "            for keyword in filtered_keywords:\n",
    "                f.write(f\"{keyword[0]} : {keyword[1]:.4f}\\n\")\n",
    "            f.write(\"----------------------------------------------------\\n\")\n",
    "\n",
    "    # Stockage des mots-clés dans un dataframe\n",
    "    df = pd.DataFrame(keywords_ODD, columns=[\"Mots-cles\", \"Scores\", \"Cibles\"])\n",
    "\n",
    "    print(\"Regroupement des mots-clés par cible...\\n\")\n",
    "    # Enregistrer les mots-clés par cibles\n",
    "    grouped = df.groupby(\"Cibles\")\n",
    "    for target, group in grouped:\n",
    "        output_filename = f\"{dossier_path}/Cible_{odd_number}-{target}.txt\"\n",
    "        # Écrire les mots-clés et leurs scores dans le fichier texte\n",
    "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Mots-clés pour la cible {target} :\\n\")\n",
    "            f.write(\"----------------------------------------------------\\n\")\n",
    "            for index, row in group.iterrows():\n",
    "                f.write(f\"{row['Mots-cles']} : {row['Scores']:.4f}\\n\")\n",
    "            f.write(\"----------------------------------------------------\\n\")\n",
    "\n",
    "    print(\"Regroupement des mots-clés par ODD...\\n\")\n",
    "    df.to_csv(f\"{dossier_path}/ODD{odd_number}.csv\", index=False)\n",
    "    \n",
    "    print(f\"...Fin de traitement de l'ODD {odd_number}\\n\")\n",
    "\n",
    "\n",
    "# entities_extractions(\"../MetaData/ODD01\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-09T14:00:40.653316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Exécution de tous les ODD\n",
    "    path = \"../MetaData\"\n",
    "    odd_files = os.listdir(path)\n",
    "    for odd_file in odd_files:\n",
    "        entities_extractions(f\"{path}/{odd_file}\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------\")"
   ],
   "id": "6954c10a7f93758e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Début de traitement de l'ODD 01...\n",
      "Extraction des mots-clés...\n",
      "\n",
      "Indicateur_01-01-01a\n",
      "Indicateur_01-01-01b\n",
      "Indicateur_01-02-01\n",
      "Indicateur_01-02-02\n",
      "Indicateur_01-03-01a\n",
      "Indicateur_01-03-01b\n",
      "Indicateur_01-04-01\n",
      "Indicateur_01-04-02\n",
      "Indicateur_01-05-01\n",
      "Indicateur_01-05-02\n",
      "Indicateur_01-05-03\n",
      "Indicateur_01-05-04\n",
      "Indicateur_01-0a-01\n",
      "Indicateur_01-0a-02a\n",
      "Indicateur_01-0a-02b\n",
      "Indicateur_01-0b-01\n",
      "Regroupement des mots-clés par cible...\n",
      "\n",
      "Regroupement des mots-clés par ODD...\n",
      "\n",
      "...Fin de traitement de l'ODD 01\n",
      "\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Début de traitement de l'ODD 02...\n",
      "Extraction des mots-clés...\n",
      "\n",
      "Indicateur_02-01-01\n",
      "Indicateur_02-01-02\n",
      "Indicateur_02-02-01\n",
      "Indicateur_02-02-02a\n",
      "Indicateur_02-02-02b\n",
      "Indicateur_02-02-03\n",
      "Indicateur_02-03-01\n",
      "Indicateur_02-03-02\n",
      "Indicateur_02-04-01\n",
      "Indicateur_02-04-01proxy\n",
      "Indicateur_02-05-01a\n",
      "Indicateur_02-05-01b\n",
      "Indicateur_02-05-02\n",
      "Indicateur_02-0A-01\n",
      "Indicateur_02-0A-02\n",
      "Indicateur_02-0B-01\n",
      "Indicateur_02-0C-01\n",
      "Regroupement des mots-clés par cible...\n",
      "\n",
      "Regroupement des mots-clés par ODD...\n",
      "\n",
      "...Fin de traitement de l'ODD 02\n",
      "\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Début de traitement de l'ODD 03...\n",
      "Extraction des mots-clés...\n",
      "\n",
      "Indicateur_03-01-01\n",
      "Indicateur_03-01-02\n",
      "Indicateur_03-02-01\n",
      "Indicateur_03-02-02\n",
      "Indicateur_03-03-01\n",
      "Indicateur_03-03-02\n",
      "Indicateur_03-03-03\n",
      "Indicateur_03-03-04\n",
      "Indicateur_03-03-05\n",
      "Indicateur_03-04-01\n",
      "Indicateur_03-04-02\n",
      "Indicateur_03-05-01\n",
      "Indicateur_03-05-02\n",
      "Indicateur_03-06-01\n",
      "Indicateur_03-07-01\n",
      "Indicateur_03-07-02\n",
      "Indicateur_03-08-01\n",
      "Indicateur_03-08-02\n",
      "Indicateur_03-09-01\n",
      "Indicateur_03-09-02\n",
      "Indicateur_03-09-03\n",
      "Indicateur_03-0a-01\n",
      "Indicateur_03-0b-01\n",
      "Indicateur_03-0B-02\n",
      "Indicateur_03-0B-03\n",
      "Indicateur_03-0C-01\n",
      "Indicateur_03-0D-01\n",
      "Indicateur_03-0D-02\n",
      "Regroupement des mots-clés par cible...\n",
      "\n",
      "Regroupement des mots-clés par ODD...\n",
      "\n",
      "...Fin de traitement de l'ODD 03\n",
      "\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Début de traitement de l'ODD 04...\n",
      "Extraction des mots-clés...\n",
      "\n",
      "Indicateur_04-01-01\n",
      "Indicateur_04-01-02\n",
      "Indicateur_04-02-01\n",
      "Indicateur_04-02-02\n",
      "Indicateur_04-03-01\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
